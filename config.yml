---

# Datasets
train:
  data_list: assets/encoder_train_data.txt
  data_dirs: ["LibriTTS/train_clean"]
  max_length: 12
  speed_pertrubation: True
  masking: True

val:
  data_list: assets/encoder_val_data.txt
  data_dirs: ["LibriTTS/test_clean"]

test:
  weights: checkpoints/encoder/model.pt
  data_list: assets/encoder_test_data.txt
  data_dirs: [ "LibriTTS/test_clean" ]

# Training
epochs: 3
batch_size: 1
learning_rate: 5e-4
weight_decay: 0.0001
checkpoint_dir: checkpoints/encoder
log_dir: logs/encoder

#OneCycleLR parameters
max_lr: 1e-3
div_factor: 25.0
pct_start: 0.3

# Augmentation
freq_masking: 10
time_masking: 6
piece_length: 30

spec_params:
  sr: 16000
  n_mels: 80
  n_fft: 1024
  win_length: 1024
  hop_length: 256

channel_norm: assets/stats.npy