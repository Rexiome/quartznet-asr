---

model: quartznet5x5  # ["quartznet5x5", "quartznet10x5", "quartznet15x5"]

# Datasets
train:
  data_list: assets/encoder_train_data.txt
  data_dirs: ["LibriTTS/train_clean"]
  apply_speed_pertrubation: True
  apply_masking: True

val:
  data_list: assets/encoder_val_data.txt
  data_dirs: ["LibriTTS/test_clean"]

test:
  weights: checkpoints/encoder/model.pt
  data_list: assets/encoder_test_data.txt
  data_dirs: [ "LibriTTS/test_clean" ]

# Training
max_length: 12
epochs: 3
batch_size: 1
learning_rate: 5e-4
weight_decay: 0.0001
checkpoint_dir: checkpoints/encoder
log_dir: logs/encoder

# OneCycleLR parameters
max_lr: 1e-3
div_factor: 25.0
pct_start: 0.3

# Augmentation
speed_pertrubation: 0.1
masking:
  piece_length: 30
  freq_masking: 10
  time_masking: 6

spec_params:
  sr: 16000
  n_mels: 80
  n_fft: 1024
  win_length: 1024
  hop_length: 256

stats: assets/stats.npy